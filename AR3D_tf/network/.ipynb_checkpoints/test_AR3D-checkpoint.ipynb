{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PSQl7JrYZGGk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 17:53:56.836344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 17:54:05.175677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-26 17:54:06.200192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.200688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.201391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.201413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-07-26 17:54:06.202775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-07-26 17:54:06.204147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-26 17:54:06.204419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-26 17:54:06.205782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-26 17:54:06.206527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-07-26 17:54:06.209363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-07-26 17:54:06.246378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2\n",
      "2021-07-26 17:54:06.247415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-26 17:54:06.278014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3499910000 Hz\n",
      "2021-07-26 17:54:06.278917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43374b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-26 17:54:06.278947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-07-26 17:54:06.628586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43a3960 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-26 17:54:06.628635: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-07-26 17:54:06.628649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-07-26 17:54:06.628661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-07-26 17:54:06.644226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.646088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.647381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-26 17:54:06.647432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-07-26 17:54:06.647473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-07-26 17:54:06.647496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-26 17:54:06.647517: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-26 17:54:06.647539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-26 17:54:06.647561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-07-26 17:54:06.647583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-07-26 17:54:06.658692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2\n",
      "2021-07-26 17:54:06.658777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-07-26 17:54:08.377583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-26 17:54:08.377618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 \n",
      "2021-07-26 17:54:08.377624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N Y Y \n",
      "2021-07-26 17:54:08.377627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   Y N Y \n",
      "2021-07-26 17:54:08.377631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   Y Y N \n",
      "2021-07-26 17:54:08.379822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10266 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-07-26 17:54:08.380787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10264 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "2021-07-26 17:54:08.381621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10266 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:b3:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "with tf.device('/gpu:0'):\n",
    "    dummy_input = tf.random.normal((1,16,112,112,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7HCpYb5ZQbr",
    "outputId": "938a187f-ad1e-434a-b669-4d3b2ab9248b"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/subin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:320068)",
      "at w.execute (/home/subin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:319389)",
      "at w.start (/home/subin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:315205)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/subin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (/home/subin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329272)"
     ]
    }
   ],
   "source": [
    "def Pool3d(kernel_size,stride):\n",
    "  return tf.keras.layers.MaxPool3D(kernel_size,stride)\n",
    "\n",
    "def Conv3d(out_channel,kernel_size,activation):\n",
    "  return tf.keras.layers.Conv3D(out_channel,kernel_size, padding='same', activation=activation)\n",
    "\n",
    "def Conv3D_nonact(out_channel,kernel_size):\n",
    "  return tf.keras.layers.Conv3D(out_channel,kernel_size, padding='same', activation=None)\n",
    "\n",
    "def Softmax():\n",
    "  return tf.keras.layers.Softmax()\n",
    "\n",
    "def ReLU():\n",
    "  return tf.keras.layers.ReLU()\n",
    "\n",
    "def FC(out_dim):\n",
    "  return tf.keras.layers.Dense(out_dim)\n",
    "\n",
    "def BatchnNorm():\n",
    "  return tf.keras.layers.BatchNormalization()\n",
    "\n",
    "def DropOut(rate):\n",
    "  return tf.keras.layers.Dropout(rate)\n",
    "\n",
    "class AR3D_sequential(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(AR3D_sequential, self).__init__()\n",
    "    # sfe block\n",
    "    self.conv1 = Conv3d(64,(3,3,3),'relu')\n",
    "    self.pool1 = Pool3d((1,2,2),(1,2,2))\n",
    "    self.conv2 = Conv3d(128,(3,3,3),'relu')\n",
    "    self.pool2 = Pool3d((2,2,2),(2,2,2))\n",
    "    self.conv3_a = Conv3d(256,(3,3,3),'relu')\n",
    "    self.conv3_b = Conv3d(256,(3,3,3),'relu')\n",
    "    self.pool3 = Pool3d((2,2,2),(2,2,2))\n",
    "    self.conv4_a = Conv3d(512,(3,3,3),'relu')\n",
    "    self.conv4_b = Conv3d(512,(3,3,3),'relu')\n",
    "    self.pool4 = Pool3d((2,2,2),(2,2,2))\n",
    "\n",
    "    # r3d\n",
    "    self.r_conv1 = Conv3d(128,(1,1,1),'relu')\n",
    "    self.r_conv1_bn = BatchnNorm()\n",
    "    self.r_conv2 = Conv3d(128,(1,3,3),'relu')\n",
    "    self.r_conv2_bn = BatchnNorm()\n",
    "    self.r_conv3 = Conv3d(128,(3,1,1),'relu')\n",
    "    self.r_conv3_bn = BatchnNorm()\n",
    "    self.r_conv4 = Conv3d(512,(1,1,1),None)\n",
    "    self.r_conv4_bn = BatchnNorm()\n",
    "\n",
    "    # attention\n",
    "\n",
    "    self.reduction_ratio = 4\n",
    "    self.reduction_channel = int(512 / self.reduction_ratio)\n",
    "    self.k_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "    self.q_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "    self.v_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "    self.restore_conv = Conv3d(512,(1,1,1),None)\n",
    "\n",
    "    self.fc6 = FC(4096)\n",
    "    self.fc7 = FC(4096)\n",
    "    self.fc8 = FC(101)\n",
    "    # 101 == numclasses\n",
    "\n",
    "    self.softmax = Softmax()\n",
    "    self.relu = ReLU()\n",
    "    self.dropout = DropOut(0.5)\n",
    "\n",
    "  def call(self, x):\n",
    "    # sfe block\n",
    "    x = self.conv1(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool2(x)\n",
    "    x = self.conv3_a(x)\n",
    "    x = self.conv3_b(x)\n",
    "    x = self.pool3(x)\n",
    "    x = self.conv4_a(x)\n",
    "    x = self.conv4_b(x)\n",
    "    x = self.pool4(x)\n",
    "\n",
    "    # r3d\n",
    "    sc_r3d = x\n",
    "    x = self.r_conv1(x)\n",
    "    x = self.r_conv1_bn(x)\n",
    "    x = self.r_conv2(x)\n",
    "    x = self.r_conv2_bn(x)\n",
    "    x = self.r_conv3(x)\n",
    "    x = self.r_conv3_bn(x)\n",
    "    x = self.r_conv4(x)\n",
    "    x = self.r_conv4_bn(x)\n",
    "    x = self.relu(x + sc_r3d)\n",
    "\n",
    "    # a3d\n",
    "    sc_a3d = x\n",
    "    \n",
    "    shape = [x.shape[0],x.shape[1]*x.shape[2]*x.shape[3],int(self.reduction_channel)]\n",
    "\n",
    "    k = self.k_conv(x)\n",
    "    k = tf.reshape(k,shape)\n",
    "    q = self.q_conv(x)\n",
    "    q = tf.reshape(q,shape)\n",
    "\n",
    "    w_spatio_temporal = tf.einsum('b i c, b j c -> b i j', k, q)\n",
    "    w_channel = tf.einsum('b d i, b d j -> b i j', k, q)\n",
    "\n",
    "    w_spatio_temporal = self.softmax(w_spatio_temporal)\n",
    "\n",
    "    v = self.v_conv(x)\n",
    "    v = tf.reshape(v,shape)\n",
    "\n",
    "    # spatio_temporal\n",
    "    out = tf.einsum('b i f, b f j -> b i j', w_spatio_temporal, v)\n",
    "    out = tf.reshape(out,[x.shape[0], x.shape[1], x.shape[2], x.shape[3], int(self.reduction_channel)])\n",
    "    out = self.restore_conv(out)\n",
    "\n",
    "    x = out + sc_a3d\n",
    "\n",
    "    # classification(fc_out)\n",
    "    x = tf.reshape(x,[x.shape[0],-1])\n",
    "    x = self.fc6(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc7(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc8(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "with tf.device('/gpu:0'):\n",
    "  # dummy_input = tf.random.normal((1,16,112,112,3))\n",
    "  model = AR3D_sequential()\n",
    "  # model = mod_seq\n",
    "  out_seq = model(dummy_input)\n",
    "  print(\"out = \", out_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uCsEZQqRrNtx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out =  (1, 101)\n"
     ]
    }
   ],
   "source": [
    "def Pool3d(kernel_size,stride):\n",
    "  return tf.keras.layers.MaxPool3D(kernel_size,stride)\n",
    "\n",
    "def Conv3d(out_channel,kernel_size, activation):\n",
    "  return tf.keras.layers.Conv3D(out_channel,kernel_size, padding='same', activation=activation)\n",
    "\n",
    "def Softmax():\n",
    "  return tf.keras.layers.Softmax()\n",
    "\n",
    "def ReLU():\n",
    "  return tf.keras.layers.ReLU()\n",
    "\n",
    "def FC(out_dim):\n",
    "  return tf.keras.layers.Dense(out_dim)\n",
    "\n",
    "def BatchnNorm():\n",
    "  return tf.keras.layers.BatchNormalization()\n",
    "\n",
    "def DropOut(rate):\n",
    "  return tf.keras.layers.Dropout(rate)\n",
    "\n",
    "class sfe_block(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(sfe_block, self).__init__()\n",
    "        self.conv1 = Conv3d(64,(3,3,3),'relu')\n",
    "        self.pool1 = Pool3d((1,2,2),(1,2,2))\n",
    "        self.conv2 = Conv3d(128,(3,3,3),'relu')\n",
    "        self.pool2 = Pool3d((2,2,2),(2,2,2))\n",
    "        self.conv3_a = Conv3d(256,(3,3,3),'relu')\n",
    "        self.conv3_b = Conv3d(256,(3,3,3),'relu')\n",
    "        self.pool3 = Pool3d((2,2,2),(2,2,2))\n",
    "        self.conv4_a = Conv3d(512,(3,3,3),'relu')\n",
    "        self.conv4_b = Conv3d(512,(3,3,3),'relu')\n",
    "        self.pool4 = Pool3d((2,2,2),(2,2,2))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3_a(x)\n",
    "        x = self.conv3_b(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4_a(x)\n",
    "        x = self.conv4_b(x)\n",
    "        out = self.pool4(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class r3d_module(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(r3d_module, self).__init__()\n",
    "        self.r_conv1 = Conv3d(128,(1,1,1),'relu')\n",
    "        self.r_conv1_bn = BatchnNorm()\n",
    "        self.r_conv2 = Conv3d(128,(1,3,3),'relu')\n",
    "        self.r_conv2_bn = BatchnNorm()\n",
    "        self.r_conv3 = Conv3d(128,(3,1,1),'relu')\n",
    "        self.r_conv3_bn = BatchnNorm()\n",
    "        self.r_conv4 = Conv3d(512,(1,1,1),None)\n",
    "        self.r_conv4_bn = BatchnNorm()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.r_conv1(x)\n",
    "        x = self.r_conv1_bn(x)\n",
    "        x = self.r_conv2(x)\n",
    "        x = self.r_conv2_bn(x)\n",
    "        x = self.r_conv3(x)\n",
    "        x = self.r_conv3_bn(x)\n",
    "        x = self.r_conv4(x)\n",
    "        out = self.r_conv4_bn(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class a3d_module(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction_ratio, attention_method):\n",
    "        super(a3d_module, self).__init__()\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.reduction_channel = int(512 / self.reduction_ratio)\n",
    "        self.k_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "        self.q_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "        self.v_conv = Conv3d(self.reduction_channel,(1,1,1),None)\n",
    "        self.restore_conv = Conv3d(512,(1,1,1),None)\n",
    "\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def call(self, x):\n",
    "        shape = [x.shape[0],x.shape[1]*x.shape[2]*x.shape[3],self.reduction_channel] ## feature_size x channel\n",
    "\n",
    "        k = self.k_conv(x)\n",
    "        k = tf.reshape(k,shape)\n",
    "        q = self.q_conv(x)\n",
    "        q = tf.reshape(q,shape)\n",
    "\n",
    "        w_spatio_temporal = tf.einsum('b i c, b j c -> b i j', k, q)\n",
    "        # w_channel = tf.einsum('b f i, b f j -> b i j', k, q)\n",
    "\n",
    "        w_spatio_temporal = self.softmax(w_spatio_temporal)\n",
    "        # w_channel = self.softmax(w_channel)\n",
    "\n",
    "        v = self.v_conv(x)\n",
    "        v = tf.reshape(v,shape)\n",
    "\n",
    "        # spatio_temporal\n",
    "        out = tf.einsum('b i f, b f j -> b i j', w_spatio_temporal, v)\n",
    "        # out = tf.einsum('b c i, b j c -> b i j', w_channel, v) ## ?? recheck this einsum op\n",
    "        out = tf.reshape(out,[x.shape[0], x.shape[1], x.shape[2], x.shape[3], int(self.reduction_channel)])\n",
    "        out = self.restore_conv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AR3D(tf.keras.Model):\n",
    "    def __init__(self, num_classes, AR3D_V='v2', SFE_type='t1', attention_method = 'spatio_temporal', reduction_ratio = 4, hidden_unit = 4096):\n",
    "        super(AR3D, self).__init__()\n",
    "        ## sfe\n",
    "        if SFE_type == 't1':\n",
    "            self.sfe = sfe_block()\n",
    "            ## fc_input_size = 50176\n",
    "        else:\n",
    "            pass\n",
    "            # ## SFE_type == 't2'\n",
    "            # ## sfe layer from c3d's convolution layer\n",
    "            # self.sfe = c3d_conv()\n",
    "            ## fc_input_size = 8192\n",
    "        \n",
    "        ## dfe\n",
    "        self.version = AR3D_V\n",
    "        self.residual = r3d_module()\n",
    "        self.attention = a3d_module(reduction_ratio, attention_method)\n",
    "\n",
    "        ## prediction (fc)\n",
    "        self.fc6 = FC(hidden_unit)\n",
    "        self.fc7 = FC(4096)\n",
    "        self.fc8 = FC(num_classes)\n",
    "\n",
    "        self.relu = ReLU()\n",
    "        self.dropout = DropOut(0.5)\n",
    "    \n",
    "    def call(self, x):\n",
    "        ## sfe\n",
    "        x = self.sfe(x)\n",
    "\n",
    "        ## dfe\n",
    "        if self.version == 'v1':\n",
    "            ## AR3D_V == 'v1'\n",
    "            # x = self.relu(self.residual(x) + self.attention(x) + x)\n",
    "\n",
    "            sc = x\n",
    "            residual = self.residual(x)\n",
    "            attention = self.attention(x)\n",
    "            x = self.relu(attention + residual + sc)\n",
    "        else:\n",
    "            ## AR3D_V == 'v2' (default)\n",
    "            # x = self.residual(x) + x\n",
    "            # x = self.relu(x)\n",
    "            # x = self.attention(x) + x\n",
    "            sc_r3d = x\n",
    "            x = self.residual(x)\n",
    "            x = self.relu(x + sc_r3d)\n",
    "\n",
    "            sc_a3d = x \n",
    "            x = self.attention(x)\n",
    "            x = x + sc_a3d\n",
    "        \n",
    "        ## prediction\n",
    "        x = tf.reshape(x,[x.shape[0],-1])\n",
    "        x = self.fc6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc8(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "with tf.device('/gpu:0'):\n",
    "  # dummy_input = tf.random.normal((1,16,112,112,3))\n",
    "  model = AR3D(101,'v2','t1','channel',4,4096)\n",
    "  # model = mod_seq\n",
    "  out = model(dummy_input)\n",
    "  print(\"out = \", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[-0.1380957 ,  0.13519843,  0.13575816, -0.08654429,  0.0605948 ,\n",
       "         0.12852287,  0.22785139, -0.09654778,  0.05900716, -0.03293788]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 0.20497988, -0.2401298 ,  0.06043866,  0.10944473,  0.18787952,\n",
       "         0.0169337 ,  0.08604617, -0.00995584, -0.01761821,  0.11421899]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AR3D.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "12580a1d599caf4f826b1cc666db7a6a0b35851f63844b13661ec586c47d4c27"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
